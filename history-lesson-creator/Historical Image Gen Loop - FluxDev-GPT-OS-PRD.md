Title: Historical Image Gen Loop - FluxDev + GPT-OS. Purpose: Spin lesson text into Flux-ready, era-accurate pics, self-correcting on the fly. Flow—load lesson, have GPT-OS twenty B summarize it into era-action-props JSON, turn that into a raw prompt like wide vintage shot nineteen thirty Wall Street, suspenders flying ticker, film grain, no phones, then blast it through FluxDev via ComfyUI, save raw PNG. Push that to Llama three-point-two vision—score it zero-one-hundred, flag fails. If it dips under seventy-five, auto-refine using the critique, send again; once it clears, double-check with Quen two-point-five VL, same drill. Both models nod yes? Log prompt, path, scores, and park the image in keepers. Still flops after three tries? Dump to fails folder with notes. End result: clean set of images, print-ready report, no human touch needed. Tech: Python, Ollama REST for LLMs, ComfyUI for Flux, reportlab for logs—runs local on four-zero-nine-zero, eats five gig Flux and twenty B, done.